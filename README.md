# From Innovation to Controversy: Identifying the Impact of Generative LLMs on Social Media Discourse - An Analysis of Toxicity and Public Concerns

In the evolving landscape of artificial intelligence, LLMs such as ChatGPT, Llama-2, and Gemini have become very important technologies that greatly affect many sectors and job markets. Their capabilities extend from simple text generation to complex problem-solving which includes different types of reasoning tasks, and their capabilities can amaze or worry people. As these models are widely used in various tasks, the risks associated with their use also increased, as the models can provide biased responses and suffer from hallucinations . Also, their effect on social media conversations is especially significant, often leading to an increase in negative and toxic interactions. On platforms such as Twitter, discussions about LLMs frequently incorporate toxic language. This brings up important questions about how people communicate digitally in the time of advanced AI. The worries are not just about toxicity. Many people are also concerned about privacy and losing jobs to LLMs. These fears are shared by different groups of people and professionals across occupations, showing a worldwide feeling of concern. In this paper, we delve into these  critical issues by addressing several research questions:

1. After the invention of LLMs especially ChatGPT, how do people use toxic words in their conversations on social media platforms (e.g., Twitter) while discussing LLMs? How does it change over time? Which part of the world has shown more toxicity?
2. What concerns do people have about ChatGPT? Which occupations are particularly worried about ChatGPT? People from which country have shown more concern? 
3. How good are generative LLMs (e.g., Mistral-7B, Gemini) as a toxicity classifier vs baseline models (e.g., BERT, RoBERTa)? To address these questions, our method involves using toxicity classification on tweets related to ChatGPT to measure the overall sentiment of toxicity. Also, we examine occupational data from user profiles associated with these tweets, aiming to find connections between occupations and their expressed concerns. Through this study, we help understand the complex social dynamics formed by LLMs, pointing out areas of public worry and the effects on future AI management.
